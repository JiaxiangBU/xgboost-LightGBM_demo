{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"LightGBM_examples/regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    }
   ],
   "source": [
    "print('Load data...')\n",
    "df_train = pd.read_csv(data_path/'regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv(data_path/'regression.test', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[0].values\n",
    "y_test = df_test[0].values\n",
    "x_train = df_train.drop(0, axis=1).values\n",
    "x_test = df_test.drop(0, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's binary_logloss: 0.687436\n",
      "[2]\tvalid_0's binary_logloss: 0.685819\n",
      "[3]\tvalid_0's binary_logloss: 0.684125\n",
      "[4]\tvalid_0's binary_logloss: 0.68213\n",
      "[5]\tvalid_0's binary_logloss: 0.679867\n",
      "[6]\tvalid_0's binary_logloss: 0.67851\n",
      "[7]\tvalid_0's binary_logloss: 0.677043\n",
      "[8]\tvalid_0's binary_logloss: 0.675195\n",
      "[9]\tvalid_0's binary_logloss: 0.673341\n",
      "[10]\tvalid_0's binary_logloss: 0.671472\n",
      "[11]\tvalid_0's binary_logloss: 0.669595\n",
      "[12]\tvalid_0's binary_logloss: 0.667739\n",
      "[13]\tvalid_0's binary_logloss: 0.665983\n",
      "[14]\tvalid_0's binary_logloss: 0.664583\n",
      "[15]\tvalid_0's binary_logloss: 0.66293\n",
      "[16]\tvalid_0's binary_logloss: 0.661583\n",
      "[17]\tvalid_0's binary_logloss: 0.659852\n",
      "[18]\tvalid_0's binary_logloss: 0.658628\n",
      "[19]\tvalid_0's binary_logloss: 0.657021\n",
      "[20]\tvalid_0's binary_logloss: 0.655344\n",
      "[21]\tvalid_0's binary_logloss: 0.653583\n",
      "[22]\tvalid_0's binary_logloss: 0.651843\n",
      "[23]\tvalid_0's binary_logloss: 0.650253\n",
      "[24]\tvalid_0's binary_logloss: 0.648701\n",
      "[25]\tvalid_0's binary_logloss: 0.647296\n",
      "[26]\tvalid_0's binary_logloss: 0.645678\n",
      "[27]\tvalid_0's binary_logloss: 0.643965\n",
      "[28]\tvalid_0's binary_logloss: 0.642552\n",
      "[29]\tvalid_0's binary_logloss: 0.641432\n",
      "[30]\tvalid_0's binary_logloss: 0.63991\n",
      "[31]\tvalid_0's binary_logloss: 0.638312\n",
      "[32]\tvalid_0's binary_logloss: 0.636923\n",
      "[33]\tvalid_0's binary_logloss: 0.635456\n",
      "[34]\tvalid_0's binary_logloss: 0.63391\n",
      "[35]\tvalid_0's binary_logloss: 0.632664\n",
      "[36]\tvalid_0's binary_logloss: 0.631428\n",
      "[37]\tvalid_0's binary_logloss: 0.630241\n",
      "[38]\tvalid_0's binary_logloss: 0.62903\n",
      "[39]\tvalid_0's binary_logloss: 0.627897\n",
      "[40]\tvalid_0's binary_logloss: 0.626716\n",
      "[41]\tvalid_0's binary_logloss: 0.625699\n",
      "[42]\tvalid_0's binary_logloss: 0.624675\n",
      "[43]\tvalid_0's binary_logloss: 0.623696\n",
      "[44]\tvalid_0's binary_logloss: 0.622827\n",
      "[45]\tvalid_0's binary_logloss: 0.621744\n",
      "[46]\tvalid_0's binary_logloss: 0.620422\n",
      "[47]\tvalid_0's binary_logloss: 0.61943\n",
      "[48]\tvalid_0's binary_logloss: 0.618175\n",
      "[49]\tvalid_0's binary_logloss: 0.616902\n",
      "[50]\tvalid_0's binary_logloss: 0.615721\n",
      "[51]\tvalid_0's binary_logloss: 0.614766\n",
      "[52]\tvalid_0's binary_logloss: 0.613733\n",
      "[53]\tvalid_0's binary_logloss: 0.612686\n",
      "[54]\tvalid_0's binary_logloss: 0.611687\n",
      "[55]\tvalid_0's binary_logloss: 0.610844\n",
      "[56]\tvalid_0's binary_logloss: 0.610016\n",
      "[57]\tvalid_0's binary_logloss: 0.609259\n",
      "[58]\tvalid_0's binary_logloss: 0.608441\n",
      "[59]\tvalid_0's binary_logloss: 0.607272\n",
      "[60]\tvalid_0's binary_logloss: 0.606429\n",
      "[61]\tvalid_0's binary_logloss: 0.605634\n",
      "[62]\tvalid_0's binary_logloss: 0.604913\n",
      "[63]\tvalid_0's binary_logloss: 0.603811\n",
      "[64]\tvalid_0's binary_logloss: 0.602905\n",
      "[65]\tvalid_0's binary_logloss: 0.602074\n",
      "[66]\tvalid_0's binary_logloss: 0.601115\n",
      "[67]\tvalid_0's binary_logloss: 0.600125\n",
      "[68]\tvalid_0's binary_logloss: 0.599074\n",
      "[69]\tvalid_0's binary_logloss: 0.598188\n",
      "[70]\tvalid_0's binary_logloss: 0.597197\n",
      "[71]\tvalid_0's binary_logloss: 0.596389\n",
      "[72]\tvalid_0's binary_logloss: 0.595652\n",
      "[73]\tvalid_0's binary_logloss: 0.594836\n",
      "[74]\tvalid_0's binary_logloss: 0.59386\n",
      "[75]\tvalid_0's binary_logloss: 0.593158\n",
      "[76]\tvalid_0's binary_logloss: 0.592427\n",
      "[77]\tvalid_0's binary_logloss: 0.591724\n",
      "[78]\tvalid_0's binary_logloss: 0.591269\n",
      "[79]\tvalid_0's binary_logloss: 0.590588\n",
      "[80]\tvalid_0's binary_logloss: 0.589833\n",
      "[81]\tvalid_0's binary_logloss: 0.588948\n",
      "[82]\tvalid_0's binary_logloss: 0.588131\n",
      "[83]\tvalid_0's binary_logloss: 0.587205\n",
      "[84]\tvalid_0's binary_logloss: 0.586322\n",
      "[85]\tvalid_0's binary_logloss: 0.585608\n",
      "[86]\tvalid_0's binary_logloss: 0.58504\n",
      "[87]\tvalid_0's binary_logloss: 0.584552\n",
      "[88]\tvalid_0's binary_logloss: 0.584033\n",
      "[89]\tvalid_0's binary_logloss: 0.583386\n",
      "[90]\tvalid_0's binary_logloss: 0.582813\n",
      "[91]\tvalid_0's binary_logloss: 0.582159\n",
      "[92]\tvalid_0's binary_logloss: 0.581327\n",
      "[93]\tvalid_0's binary_logloss: 0.58075\n",
      "[94]\tvalid_0's binary_logloss: 0.580299\n",
      "[95]\tvalid_0's binary_logloss: 0.579784\n",
      "[96]\tvalid_0's binary_logloss: 0.579311\n",
      "[97]\tvalid_0's binary_logloss: 0.57876\n",
      "[98]\tvalid_0's binary_logloss: 0.57812\n",
      "[99]\tvalid_0's binary_logloss: 0.57748\n",
      "[100]\tvalid_0's binary_logloss: 0.576953\n",
      "Start predicting...\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 64,\n",
    "    'num_trees': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# number of leaves,will be used in feature transformation\n",
    "\n",
    "num_leaf = 64\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "# train\n",
    "\n",
    "gbm = lgb.train(params=params,\n",
    "                train_set=lgb_train,\n",
    "                valid_sets=lgb_eval)\n",
    "\n",
    "print('Start predicting...')\n",
    "\n",
    "# y_pred 分别落在 100 棵树上的哪个节点上\n",
    "\n",
    "y_pred = gbm.predict(x_train, pred_leaf=True)\n",
    "y_pred_prob = gbm.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "threshold = 0.5\n",
    "for pred in y_pred_prob:\n",
    "    result.append(1 if pred > threshold else 0)\n",
    "print('result:', result[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7000, 100) 表示7000个样本，100个树\n",
      "(7000, 28) 表示7000个样本，28个特征变量\n",
      "每个树产生了 64 个叶子。\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.__class__)\n",
    "print(y_pred.shape, \"表示7000个样本，100个树\")\n",
    "print(x_train.shape, \"表示7000个样本，28个特征变量\")\n",
    "print('每个树产生了',num_leaf,'个叶子。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed training data\n"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([y_pred.shape[0], y_pred.shape[1] * num_leaf], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, y_pred.shape[0]): \n",
    "    # temp 表示在每棵树上预测的值所在节点的序号（0,64,128,...,6436 为 100 棵树的序号，中间的值为对应树的节点序号）\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    # 构造one-hot 训练数据集\n",
    "transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed testing data\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(x_test, pred_leaf=True)\n",
    "print('Writing transformed testing data')\n",
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[1]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    # 构造one-hot 测试数据集\n",
    "    transformed_testing_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7000, 6400) 表示我们最终得到了我们的特征变量，下面就是检验 LR 和 LightGBM 的差异了\n"
     ]
    }
   ],
   "source": [
    "print(transformed_training_matrix.__class__)\n",
    "print(transformed_training_matrix.shape,'表示我们最终得到了我们的特征变量，下面就是检验 LR 和 LightGBM 的差异了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "0.5023864809081527\n",
      "The rmse of prediction is: 0.441034323269683\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print(ks_max)\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://riptutorial.com/scikit-learn/example/27960/classification-using-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "0.3188854489164087\n",
      "The rmse of prediction is: 0.46944242847539996\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "y_pred = lr.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print(ks_max)\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果没有变好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
