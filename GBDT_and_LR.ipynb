{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"LightGBM_examples/regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n"
     ]
    }
   ],
   "source": [
    "print('Load data...')\n",
    "df_train = pd.read_csv(data_path/'regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv(data_path/'regression.test', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[0].values\n",
    "y_test = df_test[0].values\n",
    "x_train = df_train.drop(0, axis=1).values\n",
    "x_test = df_test.drop(0, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[2]\ttraining's auc: 0.703772\tvalid_1's auc: 0.690902\n",
      "[4]\ttraining's auc: 0.738445\tvalid_1's auc: 0.73606\n",
      "[6]\ttraining's auc: 0.73935\tvalid_1's auc: 0.746638\n",
      "[8]\ttraining's auc: 0.74507\tvalid_1's auc: 0.754628\n",
      "[10]\ttraining's auc: 0.742922\tvalid_1's auc: 0.749097\n",
      "[12]\ttraining's auc: 0.742826\tvalid_1's auc: 0.738132\n",
      "[14]\ttraining's auc: 0.740134\tvalid_1's auc: 0.733633\n",
      "[16]\ttraining's auc: 0.738513\tvalid_1's auc: 0.732255\n",
      "[18]\ttraining's auc: 0.743956\tvalid_1's auc: 0.739986\n",
      "[20]\ttraining's auc: 0.744627\tvalid_1's auc: 0.741414\n",
      "[22]\ttraining's auc: 0.745646\tvalid_1's auc: 0.74351\n",
      "[24]\ttraining's auc: 0.745929\tvalid_1's auc: 0.744203\n",
      "[26]\ttraining's auc: 0.749257\tvalid_1's auc: 0.746573\n",
      "[28]\ttraining's auc: 0.748335\tvalid_1's auc: 0.745074\n",
      "[30]\ttraining's auc: 0.747207\tvalid_1's auc: 0.741663\n",
      "[32]\ttraining's auc: 0.746398\tvalid_1's auc: 0.740607\n",
      "[34]\ttraining's auc: 0.745564\tvalid_1's auc: 0.740317\n",
      "[36]\ttraining's auc: 0.745323\tvalid_1's auc: 0.738003\n",
      "[38]\ttraining's auc: 0.745525\tvalid_1's auc: 0.738801\n",
      "[40]\ttraining's auc: 0.745514\tvalid_1's auc: 0.739075\n",
      "[42]\ttraining's auc: 0.747427\tvalid_1's auc: 0.742816\n",
      "[44]\ttraining's auc: 0.74753\tvalid_1's auc: 0.743179\n",
      "[46]\ttraining's auc: 0.748047\tvalid_1's auc: 0.744509\n",
      "[48]\ttraining's auc: 0.748387\tvalid_1's auc: 0.745638\n",
      "[50]\ttraining's auc: 0.748905\tvalid_1's auc: 0.746912\n",
      "[52]\ttraining's auc: 0.75046\tvalid_1's auc: 0.748339\n",
      "[54]\ttraining's auc: 0.750522\tvalid_1's auc: 0.748242\n",
      "[56]\ttraining's auc: 0.750966\tvalid_1's auc: 0.748823\n",
      "[58]\ttraining's auc: 0.752278\tvalid_1's auc: 0.750226\n",
      "[60]\ttraining's auc: 0.754373\tvalid_1's auc: 0.752846\n",
      "[62]\ttraining's auc: 0.756185\tvalid_1's auc: 0.755813\n",
      "[64]\ttraining's auc: 0.756131\tvalid_1's auc: 0.756998\n",
      "[66]\ttraining's auc: 0.755783\tvalid_1's auc: 0.756805\n",
      "[68]\ttraining's auc: 0.755567\tvalid_1's auc: 0.755958\n",
      "[70]\ttraining's auc: 0.755238\tvalid_1's auc: 0.75649\n",
      "[72]\ttraining's auc: 0.756748\tvalid_1's auc: 0.75849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[74]\ttraining's auc: 0.757335\tvalid_1's auc: 0.759554\n",
      "[76]\ttraining's auc: 0.757712\tvalid_1's auc: 0.759747\n",
      "[78]\ttraining's auc: 0.759006\tvalid_1's auc: 0.76294\n",
      "[80]\ttraining's auc: 0.760164\tvalid_1's auc: 0.765988\n",
      "[82]\ttraining's auc: 0.760281\tvalid_1's auc: 0.765988\n",
      "[84]\ttraining's auc: 0.760801\tvalid_1's auc: 0.766996\n",
      "[86]\ttraining's auc: 0.76132\tvalid_1's auc: 0.767431\n",
      "[88]\ttraining's auc: 0.761753\tvalid_1's auc: 0.768068\n",
      "[90]\ttraining's auc: 0.762556\tvalid_1's auc: 0.770051\n",
      "[92]\ttraining's auc: 0.763102\tvalid_1's auc: 0.771099\n",
      "[94]\ttraining's auc: 0.763067\tvalid_1's auc: 0.771148\n",
      "[96]\ttraining's auc: 0.763695\tvalid_1's auc: 0.771494\n",
      "[98]\ttraining's auc: 0.764601\tvalid_1's auc: 0.772704\n",
      "[100]\ttraining's auc: 0.765142\tvalid_1's auc: 0.773599\n",
      "Start predicting...\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'auc'},\n",
    "    'num_leaves': 64,\n",
    "    'num_trees': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "# number of leaves,will be used in feature transformation\n",
    "\n",
    "num_leaf = 64\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "# train\n",
    "\n",
    "gbm = lgb.train(params=params,\n",
    "                train_set=lgb_train,\n",
    "                valid_sets = [lgb_train, lgb_eval],\n",
    "                verbose_eval = 2)\n",
    "\n",
    "print('Start predicting...')\n",
    "\n",
    "# y_pred 分别落在 100 棵树上的哪个节点上\n",
    "\n",
    "y_pred = gbm.predict(x_train, pred_leaf=True)\n",
    "y_pred_prob = gbm.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "threshold = 0.5\n",
    "for pred in y_pred_prob:\n",
    "    result.append(1 if pred > threshold else 0)\n",
    "print('result:', result[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7000, 100) 表示7000个样本，100个树\n",
      "(7000, 28) 表示7000个样本，28个特征变量\n",
      "每个树产生了 64 个叶子。\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.__class__)\n",
    "print(y_pred.shape, \"表示7000个样本，100个树\")\n",
    "print(x_train.shape, \"表示7000个样本，28个特征变量\")\n",
    "print('每个树产生了',num_leaf,'个叶子。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed training data\n"
     ]
    }
   ],
   "source": [
    "print('Writing transformed training data')\n",
    "transformed_training_matrix = np.zeros([y_pred.shape[0], y_pred.shape[1] * num_leaf], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, y_pred.shape[0]): \n",
    "    # temp 表示在每棵树上预测的值所在节点的序号（0,64,128,...,6436 为 100 棵树的序号，中间的值为对应树的节点序号）\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    # 构造one-hot 训练数据集\n",
    "transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed testing data\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(x_test, pred_leaf=True)\n",
    "print('Writing transformed testing data')\n",
    "transformed_testing_matrix = np.zeros([len(y_pred), len(y_pred[1]) * num_leaf], dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf + np.array(y_pred[i])\n",
    "    # 构造one-hot 测试数据集\n",
    "    transformed_testing_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(7000, 6400) 表示我们最终得到了我们的特征变量，下面就是检验 LR 和 LightGBM 的差异了\n"
     ]
    }
   ],
   "source": [
    "print(transformed_training_matrix.__class__)\n",
    "print(transformed_training_matrix.shape,'表示我们最终得到了我们的特征变量，下面就是检验 LR 和 LightGBM 的差异了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "训练集 KS 值:  0.39735731451969236\n",
      "测试集 KS 值:  0.43369453044375644\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "y_pred = gbm.predict(x_train, num_iteration=gbm.best_iteration)\n",
    "fpr, tpr, thres = roc_curve(y_train, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print('训练集 KS 值: ', ks_max)\n",
    "\n",
    "y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print('测试集 KS 值: ', ks_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://riptutorial.com/scikit-learn/example/27960/classification-using-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=0.1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "训练集 KS 值:  0.2610369747833053\n",
      "测试集 KS 值:  0.3097910216718266\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "y_pred = lr.predict_proba(x_train)[:,1]\n",
    "fpr, tpr, thres = roc_curve(y_train, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print('训练集 KS 值: ', ks_max)\n",
    "\n",
    "\n",
    "y_pred = lr.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thres = roc_curve(y_test, y_pred)\n",
    "ks = tpr - fpr\n",
    "ks_max = np.max(ks)\n",
    "print('测试集 KS 值: ', ks_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果没有变好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
